{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSADS 507 - [Name of Project]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql as mysql\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, MetaData, CHAR\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connect(host = 'msads507g3sp25.mysql.database.azure.com',\n",
    "                     port = int(3306),\n",
    "                     user = 'msads507g3sp25',\n",
    "                     password = 'ADS507project',\n",
    "                     db = 'healthcare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tommy's data sets\n",
    "\n",
    "bc_cell_attribute = pd.read_csv(\"breast-cancer-wisconsin.csv\",\n",
    "names = [\"patient_id\", \"clumpThickness\", \"uniCellSize\", \"uniCellShape\", \"marginalAdhesion\", \"singleEpithelialCellSize\", \"bareNuclei\", \"blandChromatin\", \"normalNucleoli\", \"mitosis\", \"diagnosis\"])\n",
    "\n",
    "bc_diagnostic = pd.read_csv(\"wdbc.csv\",\n",
    "names = [\"patient_id\", \"diagnosis\", \"meanRadius\", \"meanTexture\", \"meanPerimeter\", \"meanArea\", \"meanSmoothness\", \"meanCompactness\", \"meanConcavity\", \"meanConcavePoints\", \"meanSymmetry\", \"meanFractal\", \"seRadius\", \"seTexture\", \"sePerimeter\", \"seArea\", \"seSmoothness\", \"seCompactness\", \"seConcavity\", \"seConcavePoints\", \"seSymmetry\", \"seFractal\", \"worstRadius\", \"worstTexture\", \"worstPerimeter\", \"worstArea\", \"worstSmoothness\", \"worstCompactness\", \"worstConcavity\", \"worstConcavePoints\", \"worstSymmetry\", \"worstFractal\"])\n",
    "\n",
    "bc_prognostic = pd.read_csv(\"wpbc.csv\",\n",
    "names = [\"patient_id\", \"outcome\", \"outcomeTime\", \"meanRadius\", \"meanTexture\", \"meanPerimeter\", \"meanArea\", \"meanSmoothness\", \"meanCompactness\", \"meanConcavity\", \"meanConcavePoints\", \"meanSymmetry\", \"meanFractal\", \"seRadius\", \"seTexture\", \"sePerimeter\", \"seArea\", \"seSmoothness\", \"seCompactness\", \"seConcavity\", \"seConcavePoints\", \"seSymmetry\", \"seFractal\", \"worstRadius\", \"worstTexture\", \"worstPerimeter\", \"worstArea\", \"worstSmoothness\", \"worstCompactness\", \"worstConcavity\", \"worstConcavePoints\", \"worstSymmetry\", \"worstFractal\", \"tumorSize\", \"lymphNodeStatus\"])\n",
    "\n",
    "heart_disease_cleveland = pd.read_csv(\"processed.cleveland.csv\",\n",
    "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"])\n",
    "\n",
    "heart_disease_hungarian = pd.read_csv(\"processed.hungarian.csv\",\n",
    "names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"])\n",
    "\n",
    "\n",
    "# Sophie's data set\n",
    "\n",
    "heartFailure = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "\n",
    "# Davood's data sets\n",
    "\n",
    "longbeach = pd.read_csv(\"long-beach-va-corrected.csv\")\n",
    "\n",
    "cleveland = pd.read_csv(\"processed.cleveland.csv\")\n",
    "\n",
    "hungarian= pd.read_csv(\"processed.hungarian.csv\")\n",
    "\n",
    "switzerland = pd.read_csv(\"processed.switzerland.csv\")\n",
    "\n",
    "df = pd.read_csv(\"Combined_Healthcare_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tommy's Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing values in the datasets are \"?\". This block replaces the \"?\" with NA/Null values\n",
    "\n",
    "bc_cell_attribute.replace(\"?\", np.NaN, inplace = True)\n",
    "\n",
    "bc_diagnostic.replace(\"?\", np.NaN, inplace = True)\n",
    "\n",
    "bc_prognostic.replace(\"?\", np.NaN, inplace = True)\n",
    "\n",
    "heart_disease_cleveland.replace(\"?\", np.NaN, inplace = True)\n",
    "\n",
    "heart_disease_hungarian.replace(\"?\", np.NaN, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change bc_cell_attribute.diagnosis from 2 for benign, 4 for malignant to B for benign, M for malignant\n",
    "\n",
    "bc_cell_attribute['diagnosis'].replace({2: \"B\", 4: \"M\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tommy's Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breast Cancer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "engine = create_engine('mysql+pymysql://msads507g3sp25:ADS507project@msads507g3sp25.mysql.database.azure.com:3306/healthcare')\n",
    "\n",
    "# bc_cell_attribute\n",
    "\n",
    "create_bc_cell_attribute = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_cell_attribute (\n",
    "    patient_id INT,\n",
    "    clumpThickness FLOAT,\n",
    "    uniCellSize FLOAT,\n",
    "    uniCellShape FLOAT,\n",
    "    marginalAdhesion FLOAT,\n",
    "    singleEpithelialCellSize FLOAT,\n",
    "    bareNuclei FLOAT,\n",
    "    blandChromatin FLOAT,\n",
    "    normalNucleoli FLOAT,\n",
    "    mitosis FLOAT,\n",
    "    diagnosis VARCHAR(10)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_bc_cell_attribute)\n",
    "conn.commit()\n",
    "\n",
    "bc_cell_attribute.to_sql('bc_cell_attribute', con=engine, if_exists = 'replace', index = False)\n",
    "\n",
    "\n",
    "# Add Index to bc_cell_attribute\n",
    "\n",
    "update_bc_cell_attribute_index = \"\"\"\n",
    "CREATE INDEX my_row_id ON bc_cell_attribute (patient_id);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_bc_cell_attribute_index)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# bc_diagnostic\n",
    "# This is a temporary table used to manipulate SQL tables\n",
    "\n",
    "create_bc_diagnostic = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_diagnostic (\n",
    "    patient_id INT,\n",
    "    diagnosis VARCHAR(10),\n",
    "    meanRadius FLOAT,\n",
    "    meanTexture FLOAT,\n",
    "    meanPerimeter FLOAT,\n",
    "    meanArea FLOAT,\n",
    "    meanSmoothness FLOAT,\n",
    "    meanCompactness FLOAT,\n",
    "    meanConcavity FLOAT,\n",
    "    meanConcavePoints FLOAT,\n",
    "    meanSymmetry FLOAT,\n",
    "    meanFractal FLOAT,\n",
    "    seRadius FLOAT,\n",
    "    seTexture FLOAT,\n",
    "    sePerimeter FLOAT,\n",
    "    seArea FLOAT,\n",
    "    seSmoothness FLOAT,\n",
    "    seCompactness FLOAT,\n",
    "    seConcavity FLOAT,\n",
    "    seConcavePoints FLOAT,\n",
    "    seSymmetry FLOAT,\n",
    "    seFractal FLOAT,\n",
    "    worstRadius FLOAT,\n",
    "    worstTexture FLOAT,\n",
    "    worstPerimeter FLOAT,\n",
    "    worstArea FLOAT,\n",
    "    worstSmoothness FLOAT,\n",
    "    worstCompactness FLOAT,\n",
    "    worstConcavity FLOAT,\n",
    "    worstConcavePoints FLOAT,\n",
    "    worstSymmetry FLOAT,\n",
    "    worstFractal FLOAT,\n",
    "    class VARCHAR(10)\n",
    ");\n",
    " \"\"\"\n",
    "\n",
    "cursor.execute(create_bc_diagnostic)\n",
    "conn.commit()\n",
    "\n",
    "bc_diagnostic.to_sql('bc_diagnostic', con=engine, if_exists = 'replace', index = False)\n",
    "\n",
    "\n",
    "# Create a column in bc_diagnostic for class\n",
    "\n",
    "alter_bc_diagnostic_class = \"\"\"\n",
    "ALTER TABLE bc_diagnostic\n",
    "    ADD COLUMN class VARCHAR(10);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(alter_bc_diagnostic_class)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Populate the class column in bc_diagnostic\n",
    "\n",
    "update_bc_diagnostic_class = \"\"\"\n",
    "UPDATE bc_diagnostic\n",
    "    SET class = 'diagnostic';\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_bc_diagnostic_class)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# bc_prognostic\n",
    "# This is a temporary table used to manipulate SQL tables\n",
    "\n",
    "create_bc_prognostic = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_prognostic (\n",
    "    patient_id INT,\n",
    "    outcome VARCHAR(10),\n",
    "    outcomeTime FLOAT,\n",
    "    meanRadius FLOAT,\n",
    "    meanTexture FLOAT,\n",
    "    meanPerimeter FLOAT,\n",
    "    meanArea FLOAT,\n",
    "    meanSmoothness FLOAT,\n",
    "    meanCompactness FLOAT,\n",
    "    meanConcavity FLOAT,\n",
    "    meanConcavePoints FLOAT,\n",
    "    meanSymmetry FLOAT,\n",
    "    meanFractal FLOAT,\n",
    "    seRadius FLOAT,\n",
    "    seTexture FLOAT,\n",
    "    sePerimeter FLOAT,\n",
    "    seArea FLOAT,\n",
    "    seSmoothness FLOAT,\n",
    "    seCompactness FLOAT,\n",
    "    seConcavity FLOAT,\n",
    "    seConcavePoints FLOAT,\n",
    "    seSymmetry FLOAT,\n",
    "    seFractal FLOAT,\n",
    "    worstRadius FLOAT,\n",
    "    worstTexture FLOAT,\n",
    "    worstPerimeter FLOAT,\n",
    "    worstArea FLOAT,\n",
    "    worstSmoothness FLOAT,\n",
    "    worstCompactness FLOAT,\n",
    "    worstConcavity FLOAT,\n",
    "    worstConcavePoints FLOAT,\n",
    "    worstSymmetry FLOAT,\n",
    "    worstFractal FLOAT,\n",
    "    tumorSize FLOAT,\n",
    "    lymphNodeStatus FLOAT,\n",
    "    class VARCHAR(10)\n",
    ");\n",
    "\"\"\"\n",
    "                                 \n",
    "cursor.execute(create_bc_prognostic)\n",
    "conn.commit()\n",
    "\n",
    "bc_prognostic.to_sql('bc_prognostic', con=engine, if_exists = 'replace', index = False)\n",
    "\n",
    "\n",
    "# Create a column in bc_diagnostic for class\n",
    "\n",
    "alter_bc_prognostic_class = \"\"\"\n",
    "ALTER TABLE bc_prognostic\n",
    "    ADD COLUMN class VARCHAR(10);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(alter_bc_prognostic_class)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Populate the class column in bc_diagnostic\n",
    "\n",
    "update_bc_prognostic_class = \"\"\"\n",
    "UPDATE bc_prognostic\n",
    "    SET class = 'prognostic';\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_bc_prognostic_class)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# bc_assessment_info\n",
    "\n",
    "create_bc_assessment_info = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_assessment_info AS\n",
    "    SELECT patient_id, meanRadius, meanTexture, meanPerimeter, meanArea, meanSmoothness, meanCompactness, meanConcavity, meanConcavePoints, meanSymmetry, meanFractal, seRadius, seTexture, sePerimeter, seArea, seSmoothness, seCompactness, seConcavity, seConcavePoints, seSymmetry, seFractal, worstRadius, worstTexture, worstPerimeter, worstArea, worstSmoothness, worstCompactness, worstConcavity, worstConcavePoints, worstSymmetry, worstFractal, class\n",
    "    FROM bc_diagnostic\n",
    "    UNION\n",
    "    SELECT patient_id, meanRadius, meanTexture, meanPerimeter, meanArea, meanSmoothness, meanCompactness, meanConcavity, meanConcavePoints, meanSymmetry, meanFractal, seRadius, seTexture, sePerimeter, seArea, seSmoothness, seCompactness, seConcavity, seConcavePoints, seSymmetry, seFractal, worstRadius, worstTexture, worstPerimeter, worstArea, worstSmoothness, worstCompactness, worstConcavity, worstConcavePoints, worstSymmetry, worstFractal, class\n",
    "    FROM bc_prognostic;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_bc_assessment_info)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# bc_assessment_outcome\n",
    "\n",
    "create_bc_assessment_outcome = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_assessment_outcome AS\n",
    "    SELECT d.patient_id, d.diagnosis, p.outcome, p.outcomeTime\n",
    "    FROM bc_diagnostic d\n",
    "    LEFT JOIN bc_prognostic p\n",
    "    ON d.patient_id = p.patient_id\n",
    "    \n",
    "    UNION\n",
    "\n",
    "    SELECT p.patient_id, d.diagnosis, p.outcome, p.outcomeTime\n",
    "    FROM bc_diagnostic d\n",
    "    RIGHT JOIN bc_prognostic p\n",
    "    ON d.patient_id = p.patient_id;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_bc_assessment_outcome)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Create bc_assessment from bc_assessment_info and bc_assessment_outcome\n",
    "\n",
    "create_bc_assessment = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bc_assessment AS\n",
    "    SELECT a.patient_id, a.meanRadius, a.meanTexture, a.meanPerimeter, a.meanArea, a.meanSmoothness, a.meanCompactness, a.meanConcavity, a.meanConcavePoints, a.meanSymmetry, a.meanFractal, a.seRadius, a.seTexture, a.sePerimeter, a.seArea, a.seSmoothness, a.seCompactness, a.seConcavity, a.seConcavePoints, a.seSymmetry, a.seFractal, a.worstRadius, a.worstTexture, a.worstPerimeter, a.worstArea, a.worstSmoothness, a.worstCompactness, a.worstConcavity, a.worstConcavePoints, a.worstSymmetry, a.worstFractal, a.class, i.diagnosis, i.outcome, i.outcomeTime\n",
    "    FROM bc_assessment_info AS a\n",
    "    INNER JOIN bc_assessment_outcome AS i\n",
    "    ON a.patient_id = i.patient_id;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_bc_assessment)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Add Index to bc_assessment\n",
    "\n",
    "update_bc_assessment_index = \"\"\"\n",
    "CREATE INDEX my_row_id ON bc_assessment (patient_id);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_bc_assessment_index)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Modify the tables to point the foreign keys to the patient\\patient_id column\n",
    "\n",
    "# Change bc_assessment patient_id to INT from bigint\n",
    "\n",
    "modify_bc_assessment_patient_id = \"\"\"\n",
    "ALTER TABLE bc_assessment\n",
    "    MODIFY COLUMN patient_id INT NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(modify_bc_assessment_patient_id)\n",
    "conn.commit()\n",
    "\n",
    "# Connect bc_assessment patient_id to the primary table (patients)\n",
    "\n",
    "update_patient_bc_assessment = \"\"\"\n",
    "INSERT INTO patients(patient_id)\n",
    "    SELECT DISTINCT patient_id\n",
    "    FROM bc_assessment\n",
    "    WHERE patient_id NOT IN(SELECT patient_id FROM patients);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_patient_bc_assessment)\n",
    "conn.commit()\n",
    "\n",
    "# Connect bc_assessment patient_id foreign key to primary key\n",
    "\n",
    "foreign_key_bc_assessment = \"\"\"\n",
    "ALTER TABLE bc_assessment\n",
    "    ADD CONSTRAINT patient_id_bc_assessment\n",
    "    FOREIGN KEY (patient_id) REFERENCES patients(patient_id)\n",
    "    ON DELETE CASCADE\n",
    "    ON UPDATE CASCADE;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(foreign_key_bc_assessment)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Change bc_cell_attribute patient_id to INT from bigint\n",
    "\n",
    "modify_bc_cell_attribute_patient_id = \"\"\"\n",
    "ALTER TABLE bc_cell_attribute\n",
    "    MODIFY COLUMN patient_id INT NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(modify_bc_cell_attribute_patient_id)\n",
    "conn.commit()\n",
    "\n",
    "# Connect bc_cell_attribute patient_id to the primary table (patients)\n",
    "\n",
    "update_patient_bc_cell_attribute = \"\"\"\n",
    "INSERT INTO patients(patient_id)\n",
    "    SELECT DISTINCT patient_id\n",
    "    FROM bc_cell_attribute\n",
    "    WHERE patient_id NOT IN(SELECT patient_id FROM patients);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(update_patient_bc_cell_attribute)\n",
    "conn.commit()\n",
    "\n",
    "# Connect bc_cell_attribute patient_id foreign key to primary key\n",
    "\n",
    "foreign_key_bc_cell_attribute = \"\"\"\n",
    "ALTER TABLE bc_cell_attribute\n",
    "    ADD CONSTRAINT patient_id_bc_cell_attribute\n",
    "    FOREIGN KEY (patient_id) REFERENCES patients(patient_id)\n",
    "    ON DELETE CASCADE\n",
    "    ON UPDATE CASCADE\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(foreign_key_bc_cell_attribute)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# This is to remove the temporary tables\n",
    "\n",
    "drop_tables = \"\"\"\n",
    "DROP TABLES bc_diagnostic, bc_prognostic, bc_assessment_outcome, bc_assessment_info;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(drop_tables)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heart_disease_cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table and load data into the Azure database\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS heart_disease_cleveland (\n",
    "    age FLOAT,\n",
    "    sex FLOAT,\n",
    "    cp FLOAT,\n",
    "    trestbps FLOAT,\n",
    "    chol FLOAT,\n",
    "    fbs FLOAT,\n",
    "    restecg FLOAT,\n",
    "    thalach FLOAT,\n",
    "    exang FLOAT,\n",
    "    oldpeak FLOAT,\n",
    "    slope FLOAT,\n",
    "    ca FLOAT,\n",
    "    thal FLOAT,\n",
    "    num FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "engine = create_engine('mysql+pymysql://msads507g3sp25:ADS507project@msads507g3sp25.mysql.database.azure.com:3306/healthcare')\n",
    "\n",
    "heart_disease_cleveland.to_sql('heart_disease_cleveland', con=engine, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heart_disease_hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table and load data into the Azure database\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS heart_disease_hungarian (\n",
    "    age FLOAT,\n",
    "    sex FLOAT,\n",
    "    cp FLOAT,\n",
    "    trestbps FLOAT,\n",
    "    chol FLOAT,\n",
    "    fbs FLOAT,\n",
    "    restecg FLOAT,\n",
    "    thalach FLOAT,\n",
    "    exang FLOAT,\n",
    "    oldpeak FLOAT,\n",
    "    slope FLOAT,\n",
    "    ca FLOAT,\n",
    "    thal FLOAT,\n",
    "    num FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "engine = create_engine('mysql+pymysql://msads507g3sp25:ADS507project@msads507g3sp25.mysql.database.azure.com:3306/healthcare')\n",
    "\n",
    "heart_disease_hungarian.to_sql('heart_disease_hungarian', con=engine, if_exists = 'replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sophie's Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heart_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS heart_failure (\n",
    "    my_row_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    age FLOAT,\n",
    "    anaemia INT,\n",
    "    creatinine_phosphokinase INT,\n",
    "    diabetes INT,\n",
    "    ejection_fraction INT,\n",
    "    high_blood_pressure INT,\n",
    "    platelets FLOAT,\n",
    "    serum_creatinine FLOAT,\n",
    "    serum_sodium INT,\n",
    "    sex INT,\n",
    "    smoking INT,\n",
    "    time INT,\n",
    "    DEATH_EVENT INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "# Define database connection\n",
    "engine = create_engine('mysql+pymysql://msads507g3sp25:ADS507project@msads507g3sp25.mysql.database.azure.com:3306/healthcare')\n",
    "\n",
    "# Upload the DataFrame to MySQL\n",
    "heartFailure.to_sql('heart_failure', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create patients table \n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS patients (\n",
    "    patient_id INT PRIMARY KEY,\n",
    "    age FLOAT,\n",
    "    sex TINYINT(1)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions table \n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Predictions (\n",
    "    prediction_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    my_row_id BIGINT,\n",
    "    patient_id INT,\n",
    "    predicted_risk_level VARCHAR(50),\n",
    "    model_used VARCHAR(50),\n",
    "    prediction_time DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY(patient_id) REFERENCES Patients(patient_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sex back to numerical values\n",
    "heartFailure[\"sex\"] = heartFailure[\"sex\"].map({\"Female\": 0, \"Male\": 1})\n",
    "# Scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = heartFailure.drop(\"DEATH_EVENT\", axis=1)\n",
    "y = heartFailure[\"DEATH_EVENT\"]\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (assuming 'heartFailure' DataFrame exists)\n",
    "X = heartFailure.drop(columns=[\"DEATH_EVENT\"])  # Drop target variable\n",
    "y = heartFailure[\"DEATH_EVENT\"]\n",
    "\n",
    "# Save original row indices to track patients\n",
    "X[\"row_id\"] = X.index  \n",
    "\n",
    "# Scale the feature columns \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.drop(columns=[\"row_id\"]))  \n",
    "\n",
    "# Perform train-test split (preserving row indices)\n",
    "X_train, X_test, y_train, y_test, row_train, row_test = train_test_split(\n",
    "    X_scaled, y, X[\"row_id\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# logistic regression \n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, lr.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model got an accuracy score of 80%, precision of 93% that did not survive heart failure and 76% that did survive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Predictions to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities for the positive class from logistic regression model\n",
    "predicted_probs = lr.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# Convert probabilities to risk labels using numpy.where\n",
    "predicted_risk_levels = np.where(predicted_probs >= 0.5, \"High Risk\", \"Low Risk\")\n",
    "\n",
    "# Create df of predictions with row_id, predicted risk level, model used, and prediction time\n",
    "df_predictions = pd.DataFrame({\n",
    "    \"prediction_id\": row_test.values, \n",
    "    \"predicted_risk_level\": predicted_risk_levels,\n",
    "    \"model_used\": \"Logistic Regression\",\n",
    "    \"prediction_time\": pd.Timestamp.now()\n",
    "})\n",
    "\n",
    "# Define database connection\n",
    "engine = create_engine('mysql+pymysql://msads507g3sp25:ADS507project@msads507g3sp25.mysql.database.azure.com:3306/healthcare')\n",
    "\n",
    "# Insert into SQL table\n",
    "df_predictions.to_sql(\"predictions\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davood's Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN for easier handling\n",
    "df.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"\\n🛠️ Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n✅ Final Dataset Info After Preprocessing:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate boxplots for each numerical column\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Create boxplots for each numeric column\n",
    "plt.figure(figsize=(20, 30))\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(len(numeric_cols)//3 + 1, 3, i + 1)\n",
    "    sns.boxplot(y=df[col], color='skyblue')\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  \n",
    "    df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of Categorical Variables\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "print(\"\\n🛠️ Categorical Columns Analysis:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n🔹 {col} Value Counts:\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "    # Plot bar charts for categorical variables\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.countplot(x=col, data=df, palette='pastel')\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_healthcare = pd.read_csv(\"transformed_healthcare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Check column names\n",
    "print(transformed_healthcare.columns)\n",
    "\n",
    "# Plot 1: Bar chart using meanRadius and meanTexture (example)\n",
    "fig1 = px.bar(transformed_healthcare, x='meanRadius', y='meanTexture', title='Mean Texture vs Mean Radius')\n",
    "fig1.show()\n",
    "\n",
    "# Plot 2: Pie chart showing counts of different meanRadius ranges (example)\n",
    "transformed_healthcare['meanRadius_category'] = pd.cut(transformed_healthcare['meanRadius'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "fig2 = px.pie(transformed_healthcare, names='meanRadius_category', title='Distribution of Mean Radius Categories')\n",
    "fig2.show()\n",
    "\n",
    "print(\"✅ Dashboard created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase figure size\n",
    "fig1 = px.bar(transformed_healthcare, x='meanRadius', y='meanTexture', title='Mean Texture vs Mean Radius')\n",
    "\n",
    "# Make bars wider\n",
    "fig1.update_traces(marker_line_width=1.5, marker_line_color=\"black\", width=0.5)\n",
    "\n",
    "# Set a larger font and increase axis label size\n",
    "fig1.update_layout(\n",
    "    width=1000, height=600,\n",
    "    font=dict(size=16),\n",
    "    xaxis=dict(title=\"Mean Radius\", title_font=dict(size=20)),\n",
    "    yaxis=dict(title=\"Mean Texture\", title_font=dict(size=20))\n",
    ")\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(transformed_healthcare, \n",
    "                 x='meanRadius', \n",
    "                 y='meanTexture', \n",
    "                 title='Relationship Between Mean Radius and Mean Texture',\n",
    "                 opacity=0.7, \n",
    "                 color_discrete_sequence=['blue'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(transformed_healthcare, \n",
    "                   x='meanRadius', \n",
    "                   y='meanTexture', \n",
    "                   title='Distribution of Mean Texture by Mean Radius', \n",
    "                   nbins=20, \n",
    "                   opacity=0.7, \n",
    "                   color_discrete_sequence=['blue'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]  # all columns except the target\n",
    "y = df.iloc[:, -1]   # target column\n",
    "\n",
    "# Split the data (this will now work because X and y are defined)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression for classification\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply K-Means Clustering\n",
    "# Here we choose 3 clusters as an example; you can adjust this based on your data or use methods like the elbow method.\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "print(\"First few rows with clusters:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions for visualization using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', s=50)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-Means Clusters Visualization')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
